{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from Pipeline_Control.ipynb\n",
      "importing Jupyter notebook from DeepBind_Control.ipynb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/abhinav/anaconda2/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['__builtins__',\n",
       " '__doc__',\n",
       " '__file__',\n",
       " '__loader__',\n",
       " '__name__',\n",
       " 'get_ipython',\n",
       " 'pipe']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np \n",
    "import warnings\n",
    "import import_ipynb\n",
    "import Pipeline_Control as pp2\n",
    "import DeepBind_Control as db22\n",
    "import os\n",
    "import pandas as pd\n",
    "import sys\n",
    "import matplotlib.pyplot as pl\n",
    "import subprocess\n",
    "import gc\n",
    "import random\n",
    "from Bio import SeqIO\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from guppy import hpy; \n",
    "\n",
    "\n",
    "dir(db22)\n",
    "dir(pp2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_1_8_21_from_class1_file(class1file):\n",
    "    \n",
    "    file1, file_extension1 = os.path.splitext(class1file)\n",
    "    \n",
    "    f2 = \"inter_bed/class0_11files_only1821_test.bed\"\n",
    "    \n",
    "    print(\"here1: \",file1)\n",
    "    \n",
    "    #initializing filenames\n",
    "    class1_test_bed= \"inter_bed/class1_\"+file1+\"_test.bed\"\n",
    "\n",
    "    #copy entries of chr1 to class1_test_bed\n",
    "    command = '''awk '/chr1\\t/' '''+class1file+''' >> '''+class1_test_bed\n",
    "    subprocess.call(command, shell=True)\n",
    "    \n",
    "    #copy entries of chr8 to class1_test_bed\n",
    "    command = '''awk '/chr8\\t/' '''+class1file+''' >> '''+class1_test_bed\n",
    "    subprocess.call(command, shell=True)\n",
    "    \n",
    "    #copy entries of chr21 to class1_test_bed\n",
    "    command = '''awk '/chr21\\t/' '''+class1file+''' >> '''+class1_test_bed\n",
    "    subprocess.call(command, shell=True)\n",
    "    \n",
    "    \n",
    "    #removing intersections between overall class0_test (chr1,8,21 of 11 files) and class1_test_bed (chr1,8,21 of one file like IFF)\n",
    "    count, num_in_class0, num_in_class1 = pp2.pipe(class1_test_bed,f2)\n",
    "    \n",
    "    \n",
    "    #remove 1, 8, 21 from class1 train and return \n",
    "    command='''sed -i '/chr1\\t/d' ./'''+class1file\n",
    "    subprocess.call(command, shell=True)\n",
    "\n",
    "    command='''sed -i '/chr8/d' ./'''+class1file\n",
    "    subprocess.call(command, shell=True)\n",
    "\n",
    "    command='''sed -i '/chr21/d' ./'''+class1file\n",
    "    subprocess.call(command, shell=True)\n",
    "    \n",
    "    return class1file,  count, num_in_class0, num_in_class1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def converter(sequence):\n",
    "    new_sequence=[]\n",
    "    for i in range(len(sequence)):\n",
    "        if sequence[i]=='a' or sequence[i]=='A':\n",
    "            new_sequence.append('T')\n",
    "        elif sequence[i]=='c' or sequence[i]=='C':\n",
    "            new_sequence.append('G')\n",
    "        elif sequence[i]=='g' or sequence[i]=='G':\n",
    "            new_sequence.append('C')\n",
    "        elif sequence[i]=='t' or sequence[i]=='T':\n",
    "            new_sequence.append('A')\n",
    "        \n",
    "            \n",
    "    str1 = ''.join(new_sequence)\n",
    "    str1=''.join(reversed(str1))\n",
    "    \n",
    "    return str1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filenames1 = ['ENCFF183UQD_H3K4me1.bed','ENCFF322IFF_H3K27me3.bed','ENCFF498CMP_H3K36me3.bed']\n",
    "#filenames1 = ['ENCFF127XXD_H3K4me3.bed','ENCFF099LMD_H3K4me2.bed', 'ENCFF139CKE_H4K20me1.bed', 'ENCFF183UQD_H3K4me1.bed','ENCFF322IFF_H3K27me3.bed','ENCFF498CMP_H3K36me3.bed', 'ENCFF578UBP_H3K27ac.bed', 'ENCFF624XRN_H2AFZ.bed', 'ENCFF737AMS_H3K4me3.bed', 'ENCFF894VEM_H3K9me3.bed']\n",
    "#filenames1 = ['ENCFF578UBP_H3K27ac.bed', 'ENCFF624XRN_H2AFZ.bed', 'ENCFF737AMS_H3K4me3.bed', 'ENCFF894VEM_H3K9me3.bed','ENCFF127XXD_H3K4me3.bed','ENCFF099LMD_H3K4me2.bed', 'ENCFF139CKE_H4K20me1.bed','ENCFF183UQD_H3K4me1.bed','ENCFF322IFF_H3K27me3.bed','ENCFF498CMP_H3K36me3.bed']\n",
    "\n",
    "filenames1=['ENCFF322IFF_H3K27me3.bed']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "df_final = pd.DataFrame(columns=['File1','File2','Accuracy', 'Scores_Array'])\n",
    "\n",
    "print len(filenames1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def classify(f1):\n",
    "    count=0\n",
    "    f1,  num_intersections, num_in_class0, num_in_class1 = remove_1_8_21_from_class1_file(f1)     #f1=class1_train.bed w/o 1,8,21\n",
    "    f2 = \"./class0.bed\"        \n",
    "\n",
    "\n",
    "    print(\"f1: \",f1)\n",
    "    print(\"f2: \",f2)\n",
    "\n",
    "    num_intersections_train, num_in_class0_train, num_in_class1_train = pp2.pipe(\"./\"+f1,f2)\n",
    "\n",
    "    file1, file_extension1 = os.path.splitext(f1)\n",
    "    f1=file1.split(\"/\")\n",
    "    print(\"f1 is:\",f1[0])\n",
    "\n",
    "    class0_train= \"inter_fa/class0.fa\"\n",
    "    class1_train= \"inter_fa/\"+f1[0]+\".fa\"\n",
    "    class0_test=\"inter_fa/class0_11files_only1821_test.fa\"\n",
    "    class1_test = \"inter_fa/class1_\"+f1[0] +\"_test.fa\" \n",
    "\n",
    "    list0=[]\n",
    "    list1=[]\n",
    "\n",
    "    #making dataframe for train data\n",
    "    for record in SeqIO.parse(class0_train, \"fasta\"):\n",
    "        if 'N' not in str(record.seq):\n",
    "            sequence=str(record.seq)+\"NNNNNNNNNN\"+str(converter(record.seq))\n",
    "            list0.append(sequence)\n",
    "    for record in SeqIO.parse(class1_train, \"fasta\"):\n",
    "        if 'N' not in str(record.seq):\n",
    "            sequence=str(record.seq)+\"NNNNNNNNNN\"+str(converter(record.seq))\n",
    "            list1.append(sequence)\n",
    "    target=[]\n",
    "\n",
    "#     random.shuffle(list0)\n",
    "#     random.shuffle(list1)\n",
    "#     list0= list0[:20000]\n",
    "#     list1= list1[:20000]\n",
    "    \n",
    "    for t in range(len(list0)):\n",
    "        target.append(0)\n",
    "\n",
    "    for m in range(len(list1)):\n",
    "        target.append(1)\n",
    "\n",
    "    sequences=list0+list1\n",
    "    \n",
    "    \n",
    "\n",
    "    dictionary = {'seq': sequences, 'target': target}\n",
    "    df_train = pd.DataFrame(dictionary)\n",
    "\n",
    "    \n",
    "    del list0\n",
    "    del list1\n",
    "    list0=[]\n",
    "    list1=[]\n",
    "\n",
    "    #making dataframe for test data\n",
    "    for record in SeqIO.parse(class0_test, \"fasta\"):\n",
    "        if 'N' not in str(record.seq):\n",
    "            sequence=str(record.seq)+\"NNNNNNNNNN\"+str(converter(record.seq))\n",
    "            list0.append(sequence)\n",
    "    for record in SeqIO.parse(class1_test, \"fasta\"):\n",
    "        if 'N' not in str(record.seq):\n",
    "            sequence=str(record.seq)+\"NNNNNNNNNN\"+str(converter(record.seq))\n",
    "            list1.append(sequence)\n",
    "    target=[]\n",
    "\n",
    "#     random.shuffle(list0)\n",
    "#     random.shuffle(list1)\n",
    "#     list0= list0[:10000]\n",
    "#     list1= list1[:10000]\n",
    "\n",
    "    for t in range(len(list0)):\n",
    "        target.append(0)\n",
    "\n",
    "    for m in range(len(list1)):\n",
    "        target.append(1)\n",
    "\n",
    "    sequences=list0+list1\n",
    "\n",
    "    dictionary = {'seq': sequences, 'target': target}\n",
    "    df_test = pd.DataFrame(dictionary)\n",
    "\n",
    "    print(df_train.shape)\n",
    "    print(df_test.shape)\n",
    "\n",
    "\n",
    "    #calling deepbind\n",
    "    accuracy,scores= db22.deepbind1(df_train,df_train,count)\n",
    "    #         print(\"Num intersections in 30%: \",num_intersections_in30,\"\\n\")\n",
    "    #         print(\"Num in class0: \",num_in_class0,\"\\n\")\n",
    "    #         print(\"Num in class1: \",num_in_class1,\"\\n\")\n",
    "    print(\"File1: \",f1,\"\\n\")\n",
    "    print(\"File2: \",f2,\"\\n\")\n",
    "    print(\"Accuracy: \",accuracy,\"\\n\")\n",
    "    print(\"Prob: \",scores,\"\\n\")\n",
    "    print (\"Scores size array\" , len(scores), \"\\n\")\n",
    "    #print(\"Probability: \",scores,\"\\n\")\n",
    "    df_final.loc[count,['File1']] = str(f1)\n",
    "    df_final.loc[count, ['File2']] = str(f2)\n",
    "    df_final.loc[count, ['Accuracy']] = accuracy\n",
    "    df_final.loc[count, ['Scores_Array']] = str(scores)\n",
    "\n",
    "\n",
    "\n",
    "    file2, file_extension2 = os.path.splitext(f2)\n",
    "    f2=file2.split(\"/\")\n",
    "    print(\"f2 is:\",f2[1])\n",
    "\n",
    "\n",
    "    #histogram stuff\n",
    "    title1=\"Class0 num: \"+str(num_in_class0)+\" Class1 num: \"+str(num_in_class1)+\" Num. of intersections: \"+str(num_intersections)\n",
    "    plot_title= \"histograms/\"+str(f1)+\"_\"+str(f2[1])+\".png\"\n",
    "    pl.figure(figsize=(7,7))\n",
    "\n",
    "    n1,bins1,patches1 = pl.hist(scores[0:num_in_class0],bins=10, density = False, edgecolor='black',alpha=0.5,label = \"class0-red\")\n",
    "    n2,bins2,patches2 = pl.hist(scores[num_in_class0+1:],bins=10, density = False, edgecolor='black',alpha=0.5, label = \"class1-black\")\n",
    "    for p in patches1:\n",
    "        pl.text(p.get_x() + p.get_width()/2., p.get_height(), '%d' % int(p.get_height()),fontsize=12, color='red', ha='center', va='bottom')\n",
    "    for p in patches2:\n",
    "        pl.text(p.get_x() + p.get_width()/2., p.get_height(), '%d' % int(p.get_height()),fontsize=12, color='black', ha='center', va='bottom')\n",
    "    pl.title(title1)\n",
    "    pl.xlabel(\"Predicted probabilities\")\n",
    "    pl.ylabel(\"Frequency\")\n",
    "    pl.legend(loc='upper left')\n",
    "    pl.savefig(plot_title)\n",
    "    pl.clf()\n",
    "    print(\"Printing Stats\")\n",
    "    h=hpy()\n",
    "    print(h.heap())\n",
    "    print(\"\\n\")\n",
    "    del list0\n",
    "    del list1\n",
    "    del df_train\n",
    "    del df_test\n",
    "    gc.collect()\n",
    "    \n",
    "\n",
    "    count=count+1\n",
    "    \n",
    "    return accuracy, scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('here1: ', 'ENCFF578UBP_H3K27ac')\n",
      "('in pipeline: f1', 'inter_bed/class1_ENCFF578UBP_H3K27ac_test.bed')\n",
      "('in pipeline: f2', 'inter_bed/class0_11files_only1821_test.bed')\n",
      "('Filename 1 in pipe:', ['inter_bed', 'class1_ENCFF578UBP_H3K27ac_test'])\n",
      "('Filename 2 in pipe:', ['inter_bed', 'class0_11files_only1821_test'])\n",
      "0\n",
      "('f1: ', 'ENCFF578UBP_H3K27ac.bed')\n",
      "('f2: ', './class0.bed')\n",
      "('in pipeline: f1', './ENCFF578UBP_H3K27ac.bed')\n",
      "('in pipeline: f2', './class0.bed')\n",
      "('Filename 1 in pipe:', ['.', 'ENCFF578UBP_H3K27ac'])\n",
      "('Filename 2 in pipe:', ['.', 'class0'])\n",
      "0\n",
      "('f1 is:', 'ENCFF578UBP_H3K27ac')\n",
      "(145651, 2)\n",
      "(28448, 2)\n",
      "('Shape is: ', (145651, 2))\n",
      "('Shape test :', (145651, 2))\n",
      "[[[0. 1. 0. 0.]\n",
      "  [0. 1. 0. 0.]\n",
      "  [0. 1. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 1. 0.]\n",
      "  [0. 0. 1. 0.]\n",
      "  [0. 0. 1. 0.]]\n",
      "\n",
      " [[0. 1. 0. 0.]\n",
      "  [0. 0. 1. 0.]\n",
      "  [0. 0. 0. 1.]\n",
      "  ...\n",
      "  [1. 0. 0. 0.]\n",
      "  [0. 1. 0. 0.]\n",
      "  [0. 0. 1. 0.]]\n",
      "\n",
      " [[0. 0. 1. 0.]\n",
      "  [0. 0. 0. 1.]\n",
      "  [0. 0. 0. 1.]\n",
      "  ...\n",
      "  [1. 0. 0. 0.]\n",
      "  [1. 0. 0. 0.]\n",
      "  [0. 1. 0. 0.]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0. 0. 0. 1.]\n",
      "  [0. 0. 1. 0.]\n",
      "  [1. 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. 1.]\n",
      "  [0. 1. 0. 0.]\n",
      "  [1. 0. 0. 0.]]\n",
      "\n",
      " [[1. 0. 0. 0.]\n",
      "  [0. 1. 0. 0.]\n",
      "  [0. 1. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 1. 0.]\n",
      "  [0. 0. 1. 0.]\n",
      "  [0. 0. 0. 1.]]\n",
      "\n",
      " [[0. 0. 1. 0.]\n",
      "  [1. 0. 0. 0.]\n",
      "  [0. 1. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 1. 0.]\n",
      "  [0. 0. 0. 1.]\n",
      "  [0. 1. 0. 0.]]]\n",
      "shape of train is:  (145651, 410, 4)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_2 (Conv1D)            (None, 391, 10)           810       \n",
      "=================================================================\n",
      "Total params: 810\n",
      "Trainable params: 810\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_2 (Conv1D)            (None, 391, 10)           810       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 39, 10)            0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 390)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 200)               78200     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 79,211\n",
      "Trainable params: 79,211\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/5\n",
      "145651/145651 [==============================] - 24s 168us/step - loss: 0.6863 - acc: 0.5450\n",
      "Epoch 2/5\n",
      "145651/145651 [==============================] - 24s 162us/step - loss: 0.6806 - acc: 0.5608\n",
      "Epoch 3/5\n",
      "145651/145651 [==============================] - 24s 164us/step - loss: 0.6765 - acc: 0.5693\n",
      "Epoch 4/5\n",
      "145651/145651 [==============================] - 24s 163us/step - loss: 0.6703 - acc: 0.5821\n",
      "Epoch 5/5\n",
      "145651/145651 [==============================] - 23s 161us/step - loss: 0.6583 - acc: 0.6015\n",
      "[[[0. 1. 0. 0.]\n",
      "  [0. 1. 0. 0.]\n",
      "  [0. 1. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 1. 0.]\n",
      "  [0. 0. 1. 0.]\n",
      "  [0. 0. 1. 0.]]\n",
      "\n",
      " [[0. 1. 0. 0.]\n",
      "  [0. 0. 1. 0.]\n",
      "  [0. 0. 0. 1.]\n",
      "  ...\n",
      "  [1. 0. 0. 0.]\n",
      "  [0. 1. 0. 0.]\n",
      "  [0. 0. 1. 0.]]\n",
      "\n",
      " [[0. 0. 1. 0.]\n",
      "  [0. 0. 0. 1.]\n",
      "  [0. 0. 0. 1.]\n",
      "  ...\n",
      "  [1. 0. 0. 0.]\n",
      "  [1. 0. 0. 0.]\n",
      "  [0. 1. 0. 0.]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0. 0. 0. 1.]\n",
      "  [0. 0. 1. 0.]\n",
      "  [1. 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. 1.]\n",
      "  [0. 1. 0. 0.]\n",
      "  [1. 0. 0. 0.]]\n",
      "\n",
      " [[1. 0. 0. 0.]\n",
      "  [0. 1. 0. 0.]\n",
      "  [0. 1. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 1. 0.]\n",
      "  [0. 0. 1. 0.]\n",
      "  [0. 0. 0. 1.]]\n",
      "\n",
      " [[0. 0. 1. 0.]\n",
      "  [1. 0. 0. 0.]\n",
      "  [0. 1. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 1. 0.]\n",
      "  [0. 0. 0. 1.]\n",
      "  [0. 1. 0. 0.]]]\n",
      "shape of test is :  (145651, 410, 4)\n",
      "145651/145651 [==============================] - 10s 69us/step\n",
      "('Test loss ', 0.6358839758188859)\n",
      "('Test acc ', 0.6377230503039539)\n",
      "145651/145651 [==============================] - 7s 51us/step\n",
      "[[0.15681487]\n",
      " [0.34334344]\n",
      " [0.6244261 ]\n",
      " ...\n",
      " [0.66407454]\n",
      " [0.3862894 ]\n",
      " [0.4947845 ]]\n",
      "[{u'class_name': u'Conv1D', u'config': {u'kernel_initializer': {u'class_name': u'VarianceScaling', u'config': {u'distribution': u'uniform', u'scale': 1.0, u'seed': None, u'mode': u'fan_avg'}}, u'name': u'conv1d_2', u'kernel_constraint': None, u'bias_regularizer': None, u'bias_constraint': None, u'dtype': u'float32', u'activation': u'relu', u'trainable': True, u'data_format': u'channels_last', u'padding': u'valid', u'strides': [1], u'dilation_rate': [1], u'kernel_regularizer': None, u'filters': 10, u'bias_initializer': {u'class_name': u'Zeros', u'config': {}}, u'batch_input_shape': [None, 410, 4], u'use_bias': True, u'activity_regularizer': None, u'kernel_size': [20]}}, {u'class_name': u'MaxPooling1D', u'config': {u'padding': u'valid', u'strides': [10], u'trainable': True, u'name': u'max_pooling1d_2', u'pool_size': [10]}}, {u'class_name': u'Flatten', u'config': {u'trainable': True, u'name': u'flatten_2', u'data_format': u'channels_last'}}, {u'class_name': u'Dense', u'config': {u'kernel_initializer': {u'class_name': u'VarianceScaling', u'config': {u'distribution': u'uniform', u'scale': 1.0, u'seed': None, u'mode': u'fan_avg'}}, u'name': u'dense_3', u'kernel_constraint': None, u'bias_regularizer': None, u'bias_constraint': None, u'activation': u'relu', u'trainable': True, u'kernel_regularizer': None, u'bias_initializer': {u'class_name': u'Zeros', u'config': {}}, u'units': 200, u'use_bias': True, u'activity_regularizer': None}}, {u'class_name': u'Dense', u'config': {u'kernel_initializer': {u'class_name': u'VarianceScaling', u'config': {u'distribution': u'uniform', u'scale': 1.0, u'seed': None, u'mode': u'fan_avg'}}, u'name': u'dense_4', u'kernel_constraint': None, u'bias_regularizer': None, u'bias_constraint': None, u'activation': u'sigmoid', u'trainable': True, u'kernel_regularizer': None, u'bias_initializer': {u'class_name': u'Zeros', u'config': {}}, u'units': 1, u'use_bias': True, u'activity_regularizer': None}}]\n",
      "FPR, TPR [0.00000000e+00 0.00000000e+00 1.40024644e-05 ... 9.99215862e-01\n",
      " 9.99215862e-01 1.00000000e+00] [1.34707348e-05 3.23297636e-04 3.23297636e-04 ... 9.99986529e-01\n",
      " 1.00000000e+00 1.00000000e+00]\n",
      "auc accuracy 0.6960098914231158\n",
      "('File1: ', ['ENCFF578UBP_H3K27ac'], '\\n')\n",
      "('File2: ', './class0.bed', '\\n')\n",
      "('Accuracy: ', 0.6960098914231158, '\\n')\n",
      "('Prob: ', array([[0.15681487],\n",
      "       [0.34334344],\n",
      "       [0.6244261 ],\n",
      "       ...,\n",
      "       [0.66407454],\n",
      "       [0.3862894 ],\n",
      "       [0.4947845 ]], dtype=float32), '\\n')\n",
      "('Scores size array', 145651, '\\n')\n",
      "('f2 is:', 'class0')\n",
      "Printing Stats\n",
      "Partition of a set of 1054229 objects. Total size = 157997576 bytes.\n",
      " Index  Count   %     Size   % Cumulative  % Kind (class / dict of class)\n",
      "     0 408716  39 56504352  36  56504352  36 str\n",
      "     1 260186  25 24639528  16  81143880  51 tuple\n",
      "     2  33851   3 11866960   8  93010840  59 unicode\n",
      "     3   2584   0  7981888   5 100992728  64 dict of module\n",
      "     4  52648   5  6738944   4 107731672  68 types.CodeType\n",
      "     5   6989   1  6470840   4 114202512  72 dict (no owner)\n",
      "     6  52434   5  6292080   4 120494592  76 function\n",
      "     7   5456   1  4930296   3 125424888  79 type\n",
      "     8   5455   1  4893928   3 130318816  82 dict of type\n",
      "     9  20513   2  4628552   3 134947368  85 list\n",
      "<1912 more rows. Type e.g. '_.more' to view.>\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 504x504 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "accuracy,scores = classify('ENCFF578UBP_H3K27ac.bed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6960098914231158\n"
     ]
    }
   ],
   "source": [
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.15681487]\n",
      " [0.34334344]\n",
      " [0.6244261 ]\n",
      " ...\n",
      " [0.66407454]\n",
      " [0.3862894 ]\n",
      " [0.4947845 ]]\n"
     ]
    }
   ],
   "source": [
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
