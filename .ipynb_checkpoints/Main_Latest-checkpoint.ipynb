{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from Pipeline_Control.ipynb\n",
      "importing Jupyter notebook from DeepBind_Control.ipynb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/abhinav/anaconda2/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['__builtins__',\n",
       " '__doc__',\n",
       " '__file__',\n",
       " '__loader__',\n",
       " '__name__',\n",
       " 'get_ipython',\n",
       " 'pipe']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np \n",
    "import warnings\n",
    "import import_ipynb\n",
    "import Pipeline_Control as pp2\n",
    "import DeepBind_Control as db22\n",
    "import os\n",
    "import pandas as pd\n",
    "import sys\n",
    "import matplotlib.pyplot as pl\n",
    "import subprocess\n",
    "import gc\n",
    "import random\n",
    "from Bio import SeqIO\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from guppy import hpy; \n",
    "\n",
    "\n",
    "dir(db22)\n",
    "dir(pp2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_1_8_21_from_class1_file(class1file):\n",
    "    \n",
    "    file1, file_extension1 = os.path.splitext(class1file)\n",
    "    \n",
    "    f2 = \"inter_bed/class0_11files_only1821_test.bed\"\n",
    "    \n",
    "    print(\"here1: \",file1)\n",
    "    \n",
    "    #initializing filenames\n",
    "    class1_test_bed= \"inter_bed/class1_\"+file1+\"_test.bed\"\n",
    "\n",
    "    #copy entries of chr1 to class1_test_bed\n",
    "    command = '''awk '/chr1\\t/' '''+class1file+''' >> '''+class1_test_bed\n",
    "    subprocess.call(command, shell=True)\n",
    "    \n",
    "    #copy entries of chr8 to class1_test_bed\n",
    "    command = '''awk '/chr8\\t/' '''+class1file+''' >> '''+class1_test_bed\n",
    "    subprocess.call(command, shell=True)\n",
    "    \n",
    "    #copy entries of chr21 to class1_test_bed\n",
    "    command = '''awk '/chr21\\t/' '''+class1file+''' >> '''+class1_test_bed\n",
    "    subprocess.call(command, shell=True)\n",
    "    \n",
    "    \n",
    "    #removing intersections between overall class0_test (chr1,8,21 of 11 files) and class1_test_bed (chr1,8,21 of one file like IFF)\n",
    "    count, num_in_class0, num_in_class1 = pp2.pipe(class1_test_bed,f2)\n",
    "    \n",
    "    \n",
    "    #remove 1, 8, 21 from class1 train and return \n",
    "    command='''sed -i '/chr1\\t/d' ./'''+class1file\n",
    "    subprocess.call(command, shell=True)\n",
    "\n",
    "    command='''sed -i '/chr8/d' ./'''+class1file\n",
    "    subprocess.call(command, shell=True)\n",
    "\n",
    "    command='''sed -i '/chr21/d' ./'''+class1file\n",
    "    subprocess.call(command, shell=True)\n",
    "    \n",
    "    return class1file,  count, num_in_class0, num_in_class1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def converter(sequence):\n",
    "    new_sequence=[]\n",
    "    for i in range(len(sequence)):\n",
    "        if sequence[i]=='a' or sequence[i]=='A':\n",
    "            new_sequence.append('T')\n",
    "        elif sequence[i]=='c' or sequence[i]=='C':\n",
    "            new_sequence.append('G')\n",
    "        elif sequence[i]=='g' or sequence[i]=='G':\n",
    "            new_sequence.append('C')\n",
    "        elif sequence[i]=='t' or sequence[i]=='T':\n",
    "            new_sequence.append('A')\n",
    "        \n",
    "            \n",
    "    str1 = ''.join(new_sequence)\n",
    "    str1=''.join(reversed(str1))\n",
    "    \n",
    "    return str1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filenames1 = ['ENCFF183UQD_H3K4me1.bed','ENCFF322IFF_H3K27me3.bed','ENCFF498CMP_H3K36me3.bed']\n",
    "#filenames1 = ['ENCFF127XXD_H3K4me3.bed','ENCFF099LMD_H3K4me2.bed', 'ENCFF139CKE_H4K20me1.bed', 'ENCFF183UQD_H3K4me1.bed','ENCFF322IFF_H3K27me3.bed','ENCFF498CMP_H3K36me3.bed', 'ENCFF578UBP_H3K27ac.bed', 'ENCFF624XRN_H2AFZ.bed', 'ENCFF737AMS_H3K4me3.bed', 'ENCFF894VEM_H3K9me3.bed']\n",
    "#filenames1 = ['ENCFF578UBP_H3K27ac.bed', 'ENCFF624XRN_H2AFZ.bed', 'ENCFF737AMS_H3K4me3.bed', 'ENCFF894VEM_H3K9me3.bed','ENCFF127XXD_H3K4me3.bed','ENCFF099LMD_H3K4me2.bed', 'ENCFF139CKE_H4K20me1.bed','ENCFF183UQD_H3K4me1.bed','ENCFF322IFF_H3K27me3.bed','ENCFF498CMP_H3K36me3.bed']\n",
    "\n",
    "filenames1=['ENCFF322IFF_H3K27me3.bed']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "df_final = pd.DataFrame(columns=['File1','File2','Accuracy', 'Scores_Array'])\n",
    "\n",
    "print len(filenames1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def classify(f1):\n",
    "    count=0\n",
    "    f1,  num_intersections, num_in_class0, num_in_class1 = remove_1_8_21_from_class1_file(f1)     #f1=class1_train.bed w/o 1,8,21\n",
    "    f2 = \"./class0.bed\"        \n",
    "\n",
    "\n",
    "    print(\"f1: \",f1)\n",
    "    print(\"f2: \",f2)\n",
    "\n",
    "    num_intersections_train, num_in_class0_train, num_in_class1_train = pp2.pipe(\"./\"+f1,f2)\n",
    "\n",
    "    file1, file_extension1 = os.path.splitext(f1)\n",
    "    f1=file1.split(\"/\")\n",
    "    print(\"f1 is:\",f1[0])\n",
    "\n",
    "    class0_train= \"inter_fa/class0.fa\"\n",
    "    class1_train= \"inter_fa/\"+f1[0]+\".fa\"\n",
    "    class0_test=\"inter_fa/class0_11files_only1821_test.fa\"\n",
    "    class1_test = \"inter_fa/class1_\"+f1[0] +\"_test.fa\" \n",
    "\n",
    "    list0=[]\n",
    "    list1=[]\n",
    "\n",
    "    #making dataframe for train data\n",
    "    for record in SeqIO.parse(class0_train, \"fasta\"):\n",
    "        if 'N' not in str(record.seq):\n",
    "            sequence=str(record.seq)+\"NNNNNNNNNN\"+str(converter(record.seq))\n",
    "            list0.append(sequence)\n",
    "    for record in SeqIO.parse(class1_train, \"fasta\"):\n",
    "        if 'N' not in str(record.seq):\n",
    "            sequence=str(record.seq)+\"NNNNNNNNNN\"+str(converter(record.seq))\n",
    "            list1.append(sequence)\n",
    "    target=[]\n",
    "\n",
    "#     random.shuffle(list0)\n",
    "#     random.shuffle(list1)\n",
    "#     list0= list0[:20000]\n",
    "#     list1= list1[:20000]\n",
    "    \n",
    "    for t in range(len(list0)):\n",
    "        target.append(0)\n",
    "\n",
    "    for m in range(len(list1)):\n",
    "        target.append(1)\n",
    "\n",
    "    sequences=list0+list1\n",
    "    \n",
    "    \n",
    "\n",
    "    dictionary = {'seq': sequences, 'target': target}\n",
    "    df_train = pd.DataFrame(dictionary)\n",
    "\n",
    "    \n",
    "    del list0\n",
    "    del list1\n",
    "    list0=[]\n",
    "    list1=[]\n",
    "\n",
    "    #making dataframe for test data\n",
    "    for record in SeqIO.parse(class0_test, \"fasta\"):\n",
    "        if 'N' not in str(record.seq):\n",
    "            sequence=str(record.seq)+\"NNNNNNNNNN\"+str(converter(record.seq))\n",
    "            list0.append(sequence)\n",
    "    for record in SeqIO.parse(class1_test, \"fasta\"):\n",
    "        if 'N' not in str(record.seq):\n",
    "            sequence=str(record.seq)+\"NNNNNNNNNN\"+str(converter(record.seq))\n",
    "            list1.append(sequence)\n",
    "    target=[]\n",
    "\n",
    "#     random.shuffle(list0)\n",
    "#     random.shuffle(list1)\n",
    "#     list0= list0[:10000]\n",
    "#     list1= list1[:10000]\n",
    "\n",
    "    for t in range(len(list0)):\n",
    "        target.append(0)\n",
    "\n",
    "    for m in range(len(list1)):\n",
    "        target.append(1)\n",
    "\n",
    "    sequences=list0+list1\n",
    "\n",
    "    dictionary = {'seq': sequences, 'target': target}\n",
    "    df_test = pd.DataFrame(dictionary)\n",
    "\n",
    "    print(df_train.shape)\n",
    "    print(df_test.shape)\n",
    "\n",
    "\n",
    "    #calling deepbind\n",
    "    accuracy,scores= db22.deepbind1(df_train,df_train,count)\n",
    "    #         print(\"Num intersections in 30%: \",num_intersections_in30,\"\\n\")\n",
    "    #         print(\"Num in class0: \",num_in_class0,\"\\n\")\n",
    "    #         print(\"Num in class1: \",num_in_class1,\"\\n\")\n",
    "    print(\"File1: \",f1,\"\\n\")\n",
    "    print(\"File2: \",f2,\"\\n\")\n",
    "    print(\"Accuracy: \",accuracy,\"\\n\")\n",
    "    print(\"Prob: \",scores,\"\\n\")\n",
    "    print (\"Scores size array\" , len(scores), \"\\n\")\n",
    "    #print(\"Probability: \",scores,\"\\n\")\n",
    "    df_final.loc[count,['File1']] = str(f1)\n",
    "    df_final.loc[count, ['File2']] = str(f2)\n",
    "    df_final.loc[count, ['Accuracy']] = accuracy\n",
    "    df_final.loc[count, ['Scores_Array']] = str(scores)\n",
    "\n",
    "\n",
    "\n",
    "    file2, file_extension2 = os.path.splitext(f2)\n",
    "    f2=file2.split(\"/\")\n",
    "    print(\"f2 is:\",f2[1])\n",
    "\n",
    "\n",
    "    #histogram stuff\n",
    "    title1=\"Class0 num: \"+str(num_in_class0)+\" Class1 num: \"+str(num_in_class1)+\" Num. of intersections: \"+str(num_intersections)\n",
    "    plot_title= \"histograms/\"+str(f1)+\"_\"+str(f2[1])+\".png\"\n",
    "    pl.figure(figsize=(7,7))\n",
    "\n",
    "    n1,bins1,patches1 = pl.hist(scores[0:num_in_class0],bins=10, density = False, edgecolor='black',alpha=0.5,label = \"class0-red\")\n",
    "    n2,bins2,patches2 = pl.hist(scores[num_in_class0+1:],bins=10, density = False, edgecolor='black',alpha=0.5, label = \"class1-black\")\n",
    "    for p in patches1:\n",
    "        pl.text(p.get_x() + p.get_width()/2., p.get_height(), '%d' % int(p.get_height()),fontsize=12, color='red', ha='center', va='bottom')\n",
    "    for p in patches2:\n",
    "        pl.text(p.get_x() + p.get_width()/2., p.get_height(), '%d' % int(p.get_height()),fontsize=12, color='black', ha='center', va='bottom')\n",
    "    pl.title(title1)\n",
    "    pl.xlabel(\"Predicted probabilities\")\n",
    "    pl.ylabel(\"Frequency\")\n",
    "    pl.legend(loc='upper left')\n",
    "    pl.savefig(plot_title)\n",
    "    pl.clf()\n",
    "    print(\"Printing Stats\")\n",
    "    h=hpy()\n",
    "    print(h.heap())\n",
    "    print(\"\\n\")\n",
    "    del list0\n",
    "    del list1\n",
    "    del df_train\n",
    "    del df_test\n",
    "    gc.collect()\n",
    "    \n",
    "\n",
    "    count=count+1\n",
    "    \n",
    "    return accuracy, scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('here1: ', 'ENCFF322IFF_H3K27me3')\n",
      "('in pipeline: f1', 'inter_bed/class1_ENCFF322IFF_H3K27me3_test.bed')\n",
      "('in pipeline: f2', 'inter_bed/class0_11files_only1821_test.bed')\n",
      "('Filename 1 in pipe:', ['inter_bed', 'class1_ENCFF322IFF_H3K27me3_test'])\n",
      "('Filename 2 in pipe:', ['inter_bed', 'class0_11files_only1821_test'])\n",
      "0\n",
      "('f1: ', 'ENCFF322IFF_H3K27me3.bed')\n",
      "('f2: ', './class0.bed')\n",
      "('in pipeline: f1', './ENCFF322IFF_H3K27me3.bed')\n",
      "('in pipeline: f2', './class0.bed')\n",
      "('Filename 1 in pipe:', ['.', 'ENCFF322IFF_H3K27me3'])\n",
      "('Filename 2 in pipe:', ['.', 'class0'])\n",
      "0\n",
      "('f1 is:', 'ENCFF322IFF_H3K27me3')\n",
      "(100198, 2)\n",
      "(195861, 2)\n",
      "('Shape is: ', (100198, 2))\n",
      "('Shape test :', (195861, 2))\n",
      "[[[0. 0. 1. 0.]\n",
      "  [0. 0. 1. 0.]\n",
      "  [0. 0. 1. 0.]\n",
      "  ...\n",
      "  [0. 1. 0. 0.]\n",
      "  [0. 1. 0. 0.]\n",
      "  [0. 1. 0. 0.]]\n",
      "\n",
      " [[1. 0. 0. 0.]\n",
      "  [0. 0. 1. 0.]\n",
      "  [0. 0. 0. 1.]\n",
      "  ...\n",
      "  [1. 0. 0. 0.]\n",
      "  [0. 1. 0. 0.]\n",
      "  [0. 0. 0. 1.]]\n",
      "\n",
      " [[0. 0. 1. 0.]\n",
      "  [0. 0. 0. 1.]\n",
      "  [0. 0. 0. 1.]\n",
      "  ...\n",
      "  [1. 0. 0. 0.]\n",
      "  [1. 0. 0. 0.]\n",
      "  [0. 1. 0. 0.]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0. 1. 0. 0.]\n",
      "  [0. 0. 0. 1.]\n",
      "  [1. 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. 1.]\n",
      "  [1. 0. 0. 0.]\n",
      "  [0. 0. 1. 0.]]\n",
      "\n",
      " [[0. 1. 0. 0.]\n",
      "  [0. 0. 0. 1.]\n",
      "  [0. 0. 0. 1.]\n",
      "  ...\n",
      "  [1. 0. 0. 0.]\n",
      "  [1. 0. 0. 0.]\n",
      "  [0. 0. 1. 0.]]\n",
      "\n",
      " [[0. 0. 0. 1.]\n",
      "  [0. 0. 1. 0.]\n",
      "  [0. 1. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 1. 0.]\n",
      "  [0. 1. 0. 0.]\n",
      "  [1. 0. 0. 0.]]]\n",
      "shape of train is:  (100198, 410, 4)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_1 (Conv1D)            (None, 391, 10)           810       \n",
      "=================================================================\n",
      "Total params: 810\n",
      "Trainable params: 810\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_1 (Conv1D)            (None, 391, 10)           810       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 39, 10)            0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 390)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 200)               78200     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 79,211\n",
      "Trainable params: 79,211\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/5\n",
      "100198/100198 [==============================] - 27s 266us/step - loss: 0.5495 - acc: 0.7308\n",
      "Epoch 2/5\n",
      "100198/100198 [==============================] - 16s 165us/step - loss: 0.5126 - acc: 0.7582\n",
      "Epoch 3/5\n",
      "100198/100198 [==============================] - 16s 159us/step - loss: 0.5050 - acc: 0.7636\n",
      "Epoch 4/5\n",
      "100198/100198 [==============================] - 16s 161us/step - loss: 0.4989 - acc: 0.7657\n",
      "Epoch 5/5\n",
      "100198/100198 [==============================] - 16s 164us/step - loss: 0.4880 - acc: 0.7721\n",
      "[array([[0., 1., 0., 0.],\n",
      "       [0., 1., 0., 0.],\n",
      "       [0., 0., 0., 1.],\n",
      "       ...,\n",
      "       [1., 0., 0., 0.],\n",
      "       [0., 0., 1., 0.],\n",
      "       [0., 0., 1., 0.]])\n",
      " array([[0., 1., 0., 0.],\n",
      "       [0., 0., 0., 1.],\n",
      "       [1., 0., 0., 0.],\n",
      "       ...,\n",
      "       [0., 0., 0., 1.],\n",
      "       [1., 0., 0., 0.],\n",
      "       [0., 0., 1., 0.]])\n",
      " array([[0., 1., 0., 0.],\n",
      "       [0., 0., 0., 1.],\n",
      "       [0., 1., 0., 0.],\n",
      "       ...,\n",
      "       [0., 0., 1., 0.],\n",
      "       [1., 0., 0., 0.],\n",
      "       [0., 0., 1., 0.]])\n",
      " ...\n",
      " array([[1., 0., 0., 0.],\n",
      "       [0., 0., 1., 0.],\n",
      "       [1., 0., 0., 0.],\n",
      "       ...,\n",
      "       [0., 0., 0., 1.],\n",
      "       [0., 1., 0., 0.],\n",
      "       [0., 0., 0., 1.]])\n",
      " array([[1., 0., 0., 0.],\n",
      "       [0., 0., 0., 1.],\n",
      "       [0., 0., 1., 0.],\n",
      "       ...,\n",
      "       [0., 1., 0., 0.],\n",
      "       [1., 0., 0., 0.],\n",
      "       [0., 0., 0., 1.]])\n",
      " array([[1., 0., 0., 0.],\n",
      "       [0., 0., 1., 0.],\n",
      "       [1., 0., 0., 0.],\n",
      "       ...,\n",
      "       [0., 0., 0., 1.],\n",
      "       [0., 1., 0., 0.],\n",
      "       [0., 0., 0., 1.]])]\n",
      "shape of test is :  (195861,)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected conv1d_1_input to have 3 dimensions, but got array with shape (195861, 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-19f9556e68f9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mclassify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ENCFF322IFF_H3K27me3.bed'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-6-699d4f6ebed2>\u001b[0m in \u001b[0;36mclassify\u001b[0;34m(f1)\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;31m#calling deepbind\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m     \u001b[0maccuracy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mdb22\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepbind1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdf_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m     \u001b[0;31m#         print(\"Num intersections in 30%: \",num_intersections_in30,\"\\n\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;31m#         print(\"Num in class0: \",num_in_class0,\"\\n\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/abhinav/Downloads/trying_1_8_21_newstuff/DeepBind_Control.ipynb\u001b[0m in \u001b[0;36mdeepbind1\u001b[0;34m(df_train, df_test, count)\u001b[0m\n",
      "\u001b[0;32m/home/abhinav/anaconda2/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps)\u001b[0m\n\u001b[1;32m   1098\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1099\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m   1101\u001b[0m         \u001b[0;31m# Prepare inputs, delegate logic to `test_loop`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_uses_dynamic_learning_phase\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/abhinav/anaconda2/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m    747\u001b[0m             \u001b[0mfeed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    748\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 749\u001b[0;31m             exception_prefix='input')\n\u001b[0m\u001b[1;32m    750\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    751\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/abhinav/anaconda2/lib/python2.7/site-packages/keras/engine/training_utils.pyc\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    125\u001b[0m                         \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m                         \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' dimensions, but got array '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m                         'with shape ' + str(data_shape))\n\u001b[0m\u001b[1;32m    128\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m                     \u001b[0mdata_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking input: expected conv1d_1_input to have 3 dimensions, but got array with shape (195861, 1)"
     ]
    }
   ],
   "source": [
    "classify('ENCFF322IFF_H3K27me3.bed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
